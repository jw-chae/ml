{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.lenth</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.lenth</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.lenth  sepal.width  petal.lenth  petal.width  type\n",
       "0          5.1          3.5          1.4          0.2     0\n",
       "1          4.9          3.0          1.4          0.2     0\n",
       "2          4.7          3.2          1.3          0.2     0\n",
       "3          4.6          3.1          1.5          0.2     0\n",
       "4          5.0          3.6          1.4          0.2     0\n",
       "5          5.4          3.9          1.7          0.4     0\n",
       "6          4.6          3.4          1.4          0.3     0\n",
       "7          5.0          3.4          1.5          0.2     0\n",
       "8          4.4          2.9          1.4          0.2     0\n",
       "9          4.9          3.1          1.5          0.1     0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "for the convinience, changing type of flower to ingteger\n",
    "setosa      0\n",
    "versicolor  1 \n",
    "virginica   2\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'type']\n",
    "# data = pd.read_csv(\"./iris.data\", skiprows=1, header=None, names=col_names)\n",
    "data = pd.read_csv(\"./iris.data\")\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        ''' constructor \n",
    "        feature index : sepal and petal\n",
    "            threshold : best split data of feature\n",
    "                left  : left node\n",
    "                right : node\n",
    "                info_gain = information gain\n",
    "        '''      \n",
    "        # for decision node\n",
    "        self.feature_index = feature_index \n",
    "        self.threshold = threshold\n",
    "        self.left = left \n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        # for leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree Class\n",
    "\n",
    "마지막으로 가지치기의 비용함수(cost function)를 살펴보겠습니다. 의사결정나무는 이 비용함수를 최소로 하는 분기를 찾아내도록 학습됩니다. 아래와 같이 정의됩니다.\n",
    "\n",
    "CC(T)=Err(T)+α×L(T)  \n",
    "CC(T)=의사결정나무의 비용 복잡도(=오류가 적으면서 terminal node 수가 적은 단순한 모델일 수록 작은 값)\n",
    "\n",
    "ERR(T)=검증데이터에 대한 오분류율\n",
    "\n",
    "L(T)=terminal node의 수(구조의 복잡도)\n",
    "\n",
    "Alpha=ERR(T)와 L(T)를 결합하는 가중치(사용자에 의해 부여됨, 보통 0.01~0.1의 값을 씀)\n",
    "\n",
    "max_depth: maximum depth of the tree. If we set it to None, the tree will grow until all the leaves are pure or the hyperparameter min_samples_split has been reached.<br>\n",
    "\n",
    "min_samples_split: indicates the minimum number of observations a sheet must have to continue creating new nodes.<br>\n",
    "\n",
    "min_information_gain: the minimum amount the Information Gain must increase for the tree to continue growing.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        \n",
    "        # initialize the root of the tree \n",
    "        \"\"\" \n",
    "                root\n",
    "            nodeL   nodeR    \n",
    "        \"\"\"\n",
    "        self.root = None\n",
    "        \n",
    "        # stopping conditions\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        ''' recursive function to build the tree\n",
    "            X : attributes(sepal.lenth to petal.width)  \n",
    "            Y : type (label)\n",
    "        num_samples : row of feature\n",
    "        num_features : column of feature\n",
    "        \n",
    "        ''' \n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X) \n",
    "        print('sample:',num_samples, ' feature:',num_features)\n",
    "        # split until satisfy stopping conditions\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # find the best split\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"info_gain\"]>0: #if best split of info gain is zero, the entropy is same(chaotic) \n",
    "                # recur left\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # recur right\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # return decision node when decision tree still in condition\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "        # compute leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # return leaf node\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split \n",
    "            logic:1. take loop and list every feature of index\n",
    "                  2. list every value of features\n",
    "                  3. split dataset according to unique of feature values\n",
    "                  4. dataset value could be null, so if dataset is not null compute impormation gain\n",
    "                  5. information gain is as better as small, if current gain > max gain , change index\n",
    "        '''\n",
    "        \n",
    "        # dictionary to store the best split\n",
    "        best_split = {}\n",
    "        max_info_gain = 0 #-float(\"inf\")\n",
    "        \n",
    "        # loop over all the features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # loop over all the feature values present in the data\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # compute information gain\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    # update the best split if needed\n",
    "                    #if current information gain is bigger than max information gain, dataset is less chaotic\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "        print(\"best_split:\",best_split)           \n",
    "        # return best split\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        ''' function to split the data '''\n",
    "        \n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        print(\"threshold:\",threshold)\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        ''' function to compute information gain '''\n",
    "        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:#entropy\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        ''' function to compute entropy '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            ratio = len(y[y == cls]) / len(y)\n",
    "            entropy += -ratio * np.log2(ratio)\n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        ''' function to compute gini index '''\n",
    "        \n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            ratio = len(y[y == cls]) / len(y)\n",
    "            gini += ratio**2\n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ''' function to train the tree '''\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' function to predict new dataset '''\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' function to predict a single data point '''\n",
    "        \n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values.reshape(-1,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 120  feature: 4\n",
      "threshold: 4.3\n",
      "threshold: 4.4\n",
      "threshold: 4.6\n",
      "threshold: 4.7\n",
      "threshold: 4.8\n",
      "threshold: 4.9\n",
      "threshold: 5.0\n",
      "threshold: 5.1\n",
      "threshold: 5.2\n",
      "threshold: 5.3\n",
      "threshold: 5.4\n",
      "threshold: 5.5\n",
      "threshold: 5.6\n",
      "threshold: 5.7\n",
      "threshold: 5.8\n",
      "threshold: 5.9\n",
      "threshold: 6.0\n",
      "threshold: 6.1\n",
      "threshold: 6.2\n",
      "threshold: 6.3\n",
      "threshold: 6.4\n",
      "threshold: 6.5\n",
      "threshold: 6.6\n",
      "threshold: 6.7\n",
      "threshold: 6.8\n",
      "threshold: 6.9\n",
      "threshold: 7.0\n",
      "threshold: 7.1\n",
      "threshold: 7.2\n",
      "threshold: 7.3\n",
      "threshold: 7.4\n",
      "threshold: 7.6\n",
      "threshold: 7.7\n",
      "threshold: 7.9\n",
      "threshold: 2.0\n",
      "threshold: 2.2\n",
      "threshold: 2.3\n",
      "threshold: 2.4\n",
      "threshold: 2.5\n",
      "threshold: 2.6\n",
      "threshold: 2.7\n",
      "threshold: 2.8\n",
      "threshold: 2.9\n",
      "threshold: 3.0\n",
      "threshold: 3.1\n",
      "threshold: 3.2\n",
      "threshold: 3.3\n",
      "threshold: 3.4\n",
      "threshold: 3.5\n",
      "threshold: 3.6\n",
      "threshold: 3.7\n",
      "threshold: 3.8\n",
      "threshold: 3.9\n",
      "threshold: 4.0\n",
      "threshold: 4.1\n",
      "threshold: 4.2\n",
      "threshold: 4.4\n",
      "threshold: 1.0\n",
      "threshold: 1.1\n",
      "threshold: 1.2\n",
      "threshold: 1.3\n",
      "threshold: 1.4\n",
      "threshold: 1.5\n",
      "threshold: 1.6\n",
      "threshold: 1.7\n",
      "threshold: 1.9\n",
      "threshold: 3.0\n",
      "threshold: 3.3\n",
      "threshold: 3.5\n",
      "threshold: 3.8\n",
      "threshold: 3.9\n",
      "threshold: 4.0\n",
      "threshold: 4.1\n",
      "threshold: 4.2\n",
      "threshold: 4.3\n",
      "threshold: 4.4\n",
      "threshold: 4.5\n",
      "threshold: 4.6\n",
      "threshold: 4.7\n",
      "threshold: 4.8\n",
      "threshold: 4.9\n",
      "threshold: 5.0\n",
      "threshold: 5.1\n",
      "threshold: 5.2\n",
      "threshold: 5.3\n",
      "threshold: 5.4\n",
      "threshold: 5.5\n",
      "threshold: 5.6\n",
      "threshold: 5.7\n",
      "threshold: 5.8\n",
      "threshold: 5.9\n",
      "threshold: 6.0\n",
      "threshold: 6.1\n",
      "threshold: 6.3\n",
      "threshold: 6.4\n",
      "threshold: 6.6\n",
      "threshold: 6.7\n",
      "threshold: 6.9\n",
      "threshold: 0.1\n",
      "threshold: 0.2\n",
      "threshold: 0.3\n",
      "threshold: 0.4\n",
      "threshold: 1.0\n",
      "threshold: 1.1\n",
      "threshold: 1.2\n",
      "threshold: 1.3\n",
      "threshold: 1.4\n",
      "threshold: 1.5\n",
      "threshold: 1.6\n",
      "threshold: 1.7\n",
      "threshold: 1.8\n",
      "threshold: 1.9\n",
      "threshold: 2.0\n",
      "threshold: 2.1\n",
      "threshold: 2.2\n",
      "threshold: 2.3\n",
      "threshold: 2.4\n",
      "threshold: 2.5\n",
      "best_split: {'feature_index': 2, 'threshold': 1.9, 'dataset_left': array([[5.8, 4. , 1.2, 0.2, 0. ],\n",
      "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
      "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
      "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
      "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
      "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
      "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
      "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
      "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
      "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
      "       [5. , 3. , 1.6, 0.2, 0. ],\n",
      "       [5.1, 3.5, 1.4, 0.2, 0. ],\n",
      "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
      "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
      "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
      "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
      "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
      "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
      "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
      "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
      "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
      "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
      "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
      "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
      "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
      "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
      "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
      "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
      "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
      "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
      "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
      "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
      "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
      "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
      "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
      "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
      "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
      "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
      "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
      "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
      "       [5. , 3.4, 1.6, 0.4, 0. ]]), 'dataset_right': array([[5.7, 2.6, 3.5, 1. , 1. ],\n",
      "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
      "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
      "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
      "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
      "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
      "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
      "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
      "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
      "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
      "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
      "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
      "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
      "       [6.7, 2.5, 5.8, 1.8, 2. ],\n",
      "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
      "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
      "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
      "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
      "       [5.9, 3. , 5.1, 1.8, 2. ],\n",
      "       [6.2, 2.8, 4.8, 1.8, 2. ],\n",
      "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
      "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
      "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
      "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
      "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
      "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
      "       [5.6, 2.8, 4.9, 2. , 2. ],\n",
      "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
      "       [5. , 2. , 3.5, 1. , 1. ],\n",
      "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
      "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
      "       [6.5, 3. , 5.5, 1.8, 2. ],\n",
      "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
      "       [6.7, 3. , 5. , 1.7, 1. ],\n",
      "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
      "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
      "       [5.7, 2.5, 5. , 2. , 2. ],\n",
      "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
      "       [6. , 3. , 4.8, 1.8, 2. ],\n",
      "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
      "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
      "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
      "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
      "       [6.4, 3.2, 5.3, 2.3, 2. ],\n",
      "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
      "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
      "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
      "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
      "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
      "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
      "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
      "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
      "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
      "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
      "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
      "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
      "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
      "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
      "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
      "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
      "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
      "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
      "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
      "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
      "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
      "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
      "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
      "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
      "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
      "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
      "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
      "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
      "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
      "       [6.7, 3.1, 5.6, 2.4, 2. ]]), 'info_gain': 0.33741385372714494}\n",
      "sample: 41  feature: 4\n",
      "threshold: 4.3\n",
      "threshold: 4.4\n",
      "threshold: 4.6\n",
      "threshold: 4.7\n",
      "threshold: 4.8\n",
      "threshold: 4.9\n",
      "threshold: 5.0\n",
      "threshold: 5.1\n",
      "threshold: 5.2\n",
      "threshold: 5.3\n",
      "threshold: 5.4\n",
      "threshold: 5.5\n",
      "threshold: 5.7\n",
      "threshold: 5.8\n",
      "threshold: 2.9\n",
      "threshold: 3.0\n",
      "threshold: 3.1\n",
      "threshold: 3.2\n",
      "threshold: 3.4\n",
      "threshold: 3.5\n",
      "threshold: 3.6\n",
      "threshold: 3.7\n",
      "threshold: 3.8\n",
      "threshold: 3.9\n",
      "threshold: 4.0\n",
      "threshold: 4.1\n",
      "threshold: 4.2\n",
      "threshold: 4.4\n",
      "threshold: 1.0\n",
      "threshold: 1.1\n",
      "threshold: 1.2\n",
      "threshold: 1.3\n",
      "threshold: 1.4\n",
      "threshold: 1.5\n",
      "threshold: 1.6\n",
      "threshold: 1.7\n",
      "threshold: 1.9\n",
      "threshold: 0.1\n",
      "threshold: 0.2\n",
      "threshold: 0.3\n",
      "threshold: 0.4\n",
      "best_split: {}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'info_gain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m classifier \u001b[39m=\u001b[39m DecisionTreeClassifier(min_samples_split\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train,Y_train)\n\u001b[0;32m      3\u001b[0m classifier\u001b[39m.\u001b[39mprint_tree()\n",
      "Cell \u001b[1;32mIn [3], line 150\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39m''' function to train the tree '''\u001b[39;00m\n\u001b[0;32m    149\u001b[0m dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((X, Y), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_tree(dataset)\n",
      "Cell \u001b[1;32mIn [3], line 34\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.build_tree\u001b[1;34m(self, dataset, curr_depth)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m# check if information gain is positive\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m best_split[\u001b[39m\"\u001b[39m\u001b[39minfo_gain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m: \u001b[39m#if best split of info gain is zero, the entropy is same(chaotic) \u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[39m# recur left\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_tree(best_split[\u001b[39m\"\u001b[39;49m\u001b[39mdataset_left\u001b[39;49m\u001b[39m\"\u001b[39;49m], curr_depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     35\u001b[0m     \u001b[39m# recur right\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     right_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_tree(best_split[\u001b[39m\"\u001b[39m\u001b[39mdataset_right\u001b[39m\u001b[39m\"\u001b[39m], curr_depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn [3], line 32\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.build_tree\u001b[1;34m(self, dataset, curr_depth)\u001b[0m\n\u001b[0;32m     30\u001b[0m best_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_best_split(dataset, num_samples, num_features)\n\u001b[0;32m     31\u001b[0m \u001b[39m# check if information gain is positive\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[39mif\u001b[39;00m best_split[\u001b[39m\"\u001b[39;49m\u001b[39minfo_gain\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m: \u001b[39m#if best split of info gain is zero, the entropy is same(chaotic) \u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[39m# recur left\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     left_subtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_tree(best_split[\u001b[39m\"\u001b[39m\u001b[39mdataset_left\u001b[39m\u001b[39m\"\u001b[39m], curr_depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m     \u001b[39m# recur right\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'info_gain'"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=2)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08511fb726953861695b9cebc649e5cfa50177e02ef8da1c1316f73897c02d54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
